import os
import random

import numpy as np
import yaml

from model.ffm_learning_core import FloorFieldModel


def get_learning_dir(learning_id="Qlearning1", base_dir="output/logs"):
    learning_dir = os.path.join(base_dir, learning_id)
    os.makedirs(learning_dir, exist_ok=True)
    return learning_dir


def compute_beta(episode_step):
    if episode_step <= 50:
        return 1.0
    elif episode_step <= 150:
        return 1.0 - (episode_step - 50) / 100.0
    else:
        return 0.0


def main():
    learning_id = "Qlearning6"
    learning_dir = get_learning_dir(learning_id)
    save_config = os.path.join(learning_dir, "run_config_used.yaml")

    # è¨­å®šèª­ã¿è¾¼ã¿
    with open("config/default_config.yaml", "r") as f:
        config = yaml.safe_load(f)

    # ã‚·ãƒ¼ãƒ‰å›ºå®š
    seed = config.get("seed", None)
    if seed is not None:
        np.random.seed(seed)
        random.seed(seed)

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    map_array = np.load(config["map"])
    sff_path = config["sff"]
    full_N = config["N"]
    params = config["params"]

    num_episodes = 650
    model = None  # æœ€åˆã¯ã¾ã ç”Ÿæˆã—ãªã„ï¼ˆNãŒå¤‰ã‚ã‚‹ã‹ã‚‰ï¼‰
    
    shared_Q = {}  # â† ã“ã‚Œã‚’ä¸€ç•ªæœ€åˆã«ç”¨æ„ï¼


    for episode in range(num_episodes):
        # æœ€åˆã®500ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã¯å‰²åˆã‚’å¤‰ãˆã‚‹
        if episode < 500:
            ratio = (episode // 50 + 1)
            N = full_N * ratio // 10
            beta = 1.0
        else:
            N = full_N
            beta = compute_beta(episode - 500)

        model = FloorFieldModel(map_array, sff_path, N, params)
        model.alpha = 0.1
        model.gamma = 0.9
        model.Q = shared_Q  # â† ã“ã“ã§å…±æœ‰ã™ã‚‹ï¼ï¼

        if episode == 0:
            print(f"ğŸ‘£ Initial training with varying N for first 500 episodes.")
        elif episode == 500:
            print(f"ğŸ“‰ Now transitioning to mixed Î² Q-learning (beta < 1.0)")

        model.reset()
        step = 0
        episode_log = []

        while model.positions.shape[0] > 0:
            model.step(beta)
            episode_log.append(np.copy(model.positions))
            step += 1

            if step % 100 == 0:
                print(f"[Episode {episode}] Step {step}, Remaining: {model.positions.shape[0]}, beta={beta:.3f}")

        # ä¿å­˜
        np.save(os.path.join(learning_dir, f"episode_{episode}.npy"),
                np.array(episode_log, dtype=object))
        print(f"Episode {episode} finished in {step} steps and saved.")

    # è¨­å®šä¿å­˜
    with open(save_config, "w") as f:
        yaml.safe_dump(config, f)

    model.save_Q(f"output/logs/{learning_id}/Q.pkl")
    print(f"\nâœ… Training finished after {num_episodes} episodes.")
    print(f"ğŸ“‚ Results saved in directory: {learning_dir}")



if __name__ == "__main__":
    main()
